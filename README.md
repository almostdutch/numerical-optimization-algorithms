# numerical-optimization-algorithms
Python implementation of the most common numerical optimization techniques.
See demo*.py files for the examples and usage.

## 1D unconstrained optimization:
- Golden section algorithm  
- Fibonacci algorithm
- Newton algorithm
- Secant algorithm

## ND unconstrained optimization:
- Gradient algorithm with variable step size (steepest descent).    
- Gradient algorithm with fixed step size. 
- Gradient algorithm with variable step size based on line search
- Conjugate gradient algorithm with variable step size (steepest descent).     
- Conjugate gradient algorithm with variable step size based on line search       
- Newton's algorithm. 
- Newton's algorithm with variable step size based on line search
- Quasi-Newton algorithm with variable step size (steepest descent).       
- Quasi-Newton algorithm with variable step size based on line search       
- Naive random walk algorithm   
- Simulated annealing algorithm    
- Particle swarm optimization algorithm

## Global unconstrained optimization:
- Naive random walk algorithm   
- Simulated annealing algorithm    
- Particle swarm optimization algorithm

## System of linear equations:
- Normal equation with Tikhonov regularization
- Gradient algorithm with variable step size (steepest descent).    
- Gradient algorithm with fixed step size. 
- Gradient algorithm with variable step size based on line search
- Conjugate gradient algorithm with variable step size (steepest descent).    
- Conjugate gradient algorithm with variable step size based on line search       
- Newton's algorithm.     
- Newton's algorithm with variable step size based on line search
- Quasi-Newton algorithm with variable step size (steepest descent).
- Quasi-Newton algorithm with variable step size based on line search
- Naive random walk algorithm
- Simulated annealing algorithm
- Particle swarm optimization algorithm
      
 ## Recursive system of linear equations:
- Recursive algorithm

## Non-linear data fitting
- Levenberg - Marquardt algorithm
- Naive random walk algorithm
- Simulated annealing algorithm
- Particle swarm optimization algorithm

## Linear programming (linear objective function and linear (non)-equality constraints)
- Simplex algorithm
- Revised simplex algorithm
- Affine scaling algorithm
- Simplex algorithm with Gomory cuts (int solutions)

## Non-linear programming ((non)-linear objective function and (non)-linear (non)-equality constraints)
- Non-linear programming with equality constraints
- Non-linear programming with equality constraints

## Constrained optimization with linear (non)-equality constraints
- Projected gradient algorithm with variable step size (steepest descent).     
- Projected gradient algorithm with variable step size based on line search
- Projected conjugate gradient algorithm with variable step size (steepest descent).    
- Projected conjugate gradient algorithm with variable step size based on line search
- Projected Newton's algorithm.     
- Projected Quasi-Newton algorithm with variable step size (steepest descent).
- Projected Quasi-Newton algorithm with variable step size based on line search

## Constrained optimization with (non)-linear equality constraints
- First order lagrangian algorithm

## Constrained optimization with (non)-linear (non)-equality constraints
- First order lagrangian algorithm
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
      
